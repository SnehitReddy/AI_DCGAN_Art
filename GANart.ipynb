{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANart.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SnehitReddy/AI_DCGAN_Art/blob/master/GANart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfLJM1OvkmRs",
        "colab_type": "code",
        "outputId": "3b5c8674-e7ba-40c6-a22b-79f891ced557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!pip uninstall torch torchvision -y\n",
        "!pip install torchvision==0.1.6\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torch-1.3.0+cu100:\n",
            "  Successfully uninstalled torch-1.3.0+cu100\n",
            "Uninstalling torchvision-0.4.1+cu100:\n",
            "  Successfully uninstalled torchvision-0.4.1+cu100\n",
            "Collecting torchvision==0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/ce/39/62f84a4b2aa94a12130857c3aeaa9ad5eebd279cc331bc9c9cbeb27acc27/torchvision-0.1.6-py3-none-any.whl\n",
            "\u001b[31mERROR: fastai 1.0.59 requires torch>=1.0.0, which is not installed.\u001b[0m\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSpul0WVvbRD",
        "colab_type": "code",
        "outputId": "1318f90c-ee9f-4913-df46-a70353f34f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My\\ Drive/MLWork1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MLWork1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsMEXk0ovY63",
        "colab_type": "code",
        "outputId": "1afb0e7f-a73f-4028-ef75-04a3e2e9980f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget https://download.pytorch.org/whl/cu90/torch-0.3.1-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-06 03:24:43--  https://download.pytorch.org/whl/cu90/torch-0.3.1-cp36-cp36m-linux_x86_64.whl\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.224.2.116, 13.224.2.123, 13.224.2.121, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.224.2.116|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 547781372 (522M) [binary/octet-stream]\n",
            "Saving to: ‘torch-0.3.1-cp36-cp36m-linux_x86_64.whl’\n",
            "\n",
            "torch-0.3.1-cp36-cp 100%[===================>] 522.40M  46.2MB/s    in 11s     \n",
            "\n",
            "2019-11-06 03:24:55 (47.5 MB/s) - ‘torch-0.3.1-cp36-cp36m-linux_x86_64.whl’ saved [547781372/547781372]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyM2jGH7vn9U",
        "colab_type": "code",
        "outputId": "1f59a394-33e7-4b3e-8874-d5d48693762e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!pip install ./torch-0.3.1-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./torch-0.3.1-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.1) (1.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.1) (3.13)\n",
            "\u001b[31mERROR: fastai 1.0.59 has requirement torch>=1.0.0, but you'll have torch 0.3.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVm6_eVLymFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python ./DCGAN/make_gif.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Uki8pVynsp0",
        "colab_type": "text"
      },
      "source": [
        "# **Readme**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "This project attempts to train a Generative Adversarial Neural network to create images people would classify as artwork\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etw_lW3WwpPg",
        "colab_type": "code",
        "outputId": "50bc8f0c-d2d3-4bea-f6bc-76bb1abc293c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "source": [
        "with open('./movie.gif','rb') as f:\n",
        "    display(Image(data=f.read(), format='png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTQsSi_CzNEg",
        "colab_type": "code",
        "outputId": "8f72b7a1-f2f5-4965-9547-1c01ee50ac5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "with open('./art.gif','rb') as f:\n",
        "    display(Image(data=f.read(), format='png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRKai3-jrHT9",
        "colab_type": "text"
      },
      "source": [
        "## How to run\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This notebook has been setup to be compatible with the requirements of the network. If you wish to run this on your local machine, configure Pytorch to run with GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg8VovTirJwa",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Datasets\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This network has been teseted on the Art Images (1) (https://www.kaggle.com/thedownhill/art-images-drawings-painting-sculpture-engraving), Danbooru 2018 (2) (https://www.gwern.net/Danbooru2018), and the Anime Faces (3) dataset at http://zhuanlan.zhihu.com/p/24767059 datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0EazrLglfu2",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lfa5jwtlHC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import imageio\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBeuaPcZmlbK",
        "colab_type": "text"
      },
      "source": [
        "#Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mbmqFOjlLFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 64\n",
        "G_input_dim = 100\n",
        "G_output_dim = 3\n",
        "D_input_dim = 3\n",
        "D_output_dim = 1\n",
        "num_filters = [1024, 512, 256, 128]\n",
        "\n",
        "learning_rate = 0.0002\n",
        "betas = (0.5, 0.999)\n",
        "batch_size = 128\n",
        "num_epochs = 100\n",
        "data_dir = './DCGAN/processed_data/'\n",
        "save_dir = './DCGAN/results/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_A5xuFFmri_",
        "colab_type": "text"
      },
      "source": [
        "#Set Up DataStream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciExsP9blMM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.Scale(image_size),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "celebA_data = dsets.ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset=celebA_data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfAWzFBMm1Dg",
        "colab_type": "text"
      },
      "source": [
        "#Auxiliary Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGtpsGDRm3nw",
        "colab_type": "text"
      },
      "source": [
        "###Denormalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UEdo94AlMPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZUlcSB4m7DM",
        "colab_type": "text"
      },
      "source": [
        "#Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRoA8GRDlMR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self, input_dim, num_filters, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Hidden layers\n",
        "        self.hidden_layer = torch.nn.Sequential()\n",
        "        for i in range(len(num_filters)):\n",
        "            # Convolutional Transpose layer\n",
        "            if i == 0:\n",
        "                convt = torch.nn.ConvTranspose2d(input_dim, num_filters[i], kernel_size=4, stride=1, padding=0)\n",
        "            else:\n",
        "                convt = torch.nn.ConvTranspose2d(num_filters[i-1], num_filters[i], kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "            convt_name = 'convt' + str(i + 1)\n",
        "            self.hidden_layer.add_module(convt_name, convt)\n",
        "\n",
        "            # Initializer\n",
        "            torch.nn.init.normal(convt.weight, mean=0.0, std=0.02)\n",
        "            torch.nn.init.constant(convt.bias, 0.0)\n",
        "\n",
        "            # Batch normalization\n",
        "            bn_name = 'bn' + str(i + 1)\n",
        "            self.hidden_layer.add_module(bn_name, torch.nn.BatchNorm2d(num_filters[i]))\n",
        "\n",
        "            # Activation\n",
        "            act_name = 'act' + str(i + 1)\n",
        "            self.hidden_layer.add_module(act_name, torch.nn.ReLU())\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = torch.nn.Sequential()\n",
        "        # Convolutional Transpose layer\n",
        "        out = torch.nn.ConvTranspose2d(num_filters[i], output_dim, kernel_size=4, stride=2, padding=1)\n",
        "        self.output_layer.add_module('out', out)\n",
        "        # Initializer\n",
        "        torch.nn.init.normal(out.weight, mean=0.0, std=0.02)\n",
        "        torch.nn.init.constant(out.bias, 0.0)\n",
        "        # Activation\n",
        "        self.output_layer.add_module('act', torch.nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.hidden_layer(x)\n",
        "        out = self.output_layer(h)\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQCSBHzYnDSQ",
        "colab_type": "text"
      },
      "source": [
        "#Discriminator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xH1BBbTlMU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self, input_dim, num_filters, output_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Hidden layers\n",
        "        self.hidden_layer = torch.nn.Sequential()\n",
        "        for i in range(len(num_filters)):\n",
        "            # Convolutional layer\n",
        "            if i == 0:\n",
        "                conv = torch.nn.Conv2d(input_dim, num_filters[i], kernel_size=4, stride=2, padding=1)\n",
        "            else:\n",
        "                conv = torch.nn.Conv2d(num_filters[i-1], num_filters[i], kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "            conv_name = 'conv' + str(i + 1)\n",
        "            self.hidden_layer.add_module(conv_name, conv)\n",
        "\n",
        "            # Initializer\n",
        "            torch.nn.init.normal(conv.weight, mean=0.0, std=0.02)\n",
        "            torch.nn.init.constant(conv.bias, 0.0)\n",
        "\n",
        "            # Batch normalization\n",
        "            if i != 0:\n",
        "                bn_name = 'bn' + str(i + 1)\n",
        "                self.hidden_layer.add_module(bn_name, torch.nn.BatchNorm2d(num_filters[i]))\n",
        "\n",
        "            # Activation\n",
        "            act_name = 'act' + str(i + 1)\n",
        "            self.hidden_layer.add_module(act_name, torch.nn.LeakyReLU(0.2))\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = torch.nn.Sequential()\n",
        "        # Convolutional layer\n",
        "        out = torch.nn.Conv2d(num_filters[i], output_dim, kernel_size=4, stride=1, padding=0)\n",
        "        self.output_layer.add_module('out', out)\n",
        "        # Initializer\n",
        "        torch.nn.init.normal(out.weight, mean=0.0, std=0.02)\n",
        "        torch.nn.init.constant(out.bias, 0.0)\n",
        "        # Activation\n",
        "        self.output_layer.add_module('act', torch.nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.hidden_layer(x)\n",
        "        out = self.output_layer(h)\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMgHbLG5nF94",
        "colab_type": "text"
      },
      "source": [
        "#Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5TBh6PVnGfH",
        "colab_type": "text"
      },
      "source": [
        "##Plot losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkl1mrBmlMYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(d_losses, g_losses, num_epoch, save=False, save_dir='./DCGAN/results/', show=False):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_xlim(0, num_epochs)\n",
        "    ax.set_ylim(0, max(np.max(g_losses), np.max(d_losses))*1.1)\n",
        "    plt.xlabel('Epoch {0}'.format(num_epoch + 1))\n",
        "    plt.ylabel('Loss values')\n",
        "    plt.plot(d_losses, label='Discriminator')\n",
        "    plt.plot(g_losses, label='Generator')\n",
        "    plt.legend()\n",
        "\n",
        "    # save plot\n",
        "    if save:\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.mkdir(save_dir)\n",
        "        save_fn = save_dir + 'losses_epoch_{:d}'.format(num_epoch + 1) + '.png'\n",
        "        plt.savefig(save_fn)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg782kLAnN5c",
        "colab_type": "text"
      },
      "source": [
        "##Plot generated image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Peg4KHT1nOQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_result(generator, noise, num_epoch, save=False, save_dir='./DCGAN/results/', show=False, fig_size=(5, 5)):\n",
        "    generator.eval()\n",
        "\n",
        "    noise = Variable(noise.cuda(), volatile=True)\n",
        "    gen_image = generator(noise)\n",
        "    gen_image = denorm(gen_image)\n",
        "\n",
        "    generator.train()\n",
        "\n",
        "    n_rows = np.sqrt(noise.size()[0]).astype(np.int32)\n",
        "    n_cols = np.sqrt(noise.size()[0]).astype(np.int32)\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=fig_size)\n",
        "    for ax, img in zip(axes.flatten(), gen_image):\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box')\n",
        "        img = (((img - img.min()) * 255) / (img.max() - img.min())).cpu().data.numpy().transpose(1, 2, 0).astype(np.uint8)\n",
        "        ax.imshow(img, cmap=None, aspect='equal')\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    title = 'Epoch {0}'.format(num_epoch+1)\n",
        "    fig.text(0.5, 0.04, title, ha='center')\n",
        "\n",
        "    # save image\n",
        "    if save:\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.mkdir(save_dir)\n",
        "        save_fn = save_dir + 'image_epoch_{:d}'.format(num_epoch+1) + '.png'\n",
        "        plt.savefig(save_fn)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQP7QWDal993",
        "colab_type": "text"
      },
      "source": [
        "#Driver Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-kaaG61mAx-",
        "colab_type": "text"
      },
      "source": [
        "##Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w2YGtVUlM61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "G = Generator(G_input_dim, num_filters, G_output_dim)\n",
        "D = Discriminator(D_input_dim, num_filters[::-1], D_output_dim)\n",
        "G.cuda()\n",
        "D.cuda()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idfPQW-1mIfH",
        "colab_type": "text"
      },
      "source": [
        "##Loss Funtion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGFVfqFSmMMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "criterion = torch.nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64C8tjFnmPSn",
        "colab_type": "text"
      },
      "source": [
        "##Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvF8CFwFmVl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G_optimizer = torch.optim.Adam(G.parameters(), lr=learning_rate, betas=betas)\n",
        "D_optimizer = torch.optim.Adam(D.parameters(), lr=learning_rate, betas=betas)\n",
        "\n",
        "\n",
        "D_avg_losses = []\n",
        "G_avg_losses = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ1j3JOImWvH",
        "colab_type": "text"
      },
      "source": [
        "## Samples for GIF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ_TlfT9mamb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "num_test_samples = 5*5\n",
        "fixed_noise = torch.randn(num_test_samples, G_input_dim).view(-1, G_input_dim, 1, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhkNcPOkmc90",
        "colab_type": "text"
      },
      "source": [
        "#Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYYkHh0ilM-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    D_losses = []\n",
        "    G_losses = []\n",
        "\n",
        "    # minibatch training\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "\n",
        "        # image data\n",
        "        mini_batch = images.size()[0]\n",
        "        x_ = Variable(images.cuda())\n",
        "\n",
        "        # labels\n",
        "        y_real_ = Variable(torch.ones(mini_batch).cuda())\n",
        "        y_fake_ = Variable(torch.zeros(mini_batch).cuda())\n",
        "\n",
        "        # Train discriminator with real data\n",
        "        D_real_decision = D(x_).squeeze()\n",
        "        # print(D_real_decision, y_real_)\n",
        "        D_real_loss = criterion(D_real_decision, y_real_)\n",
        "\n",
        "        # Train discriminator with fake data\n",
        "        z_ = torch.randn(mini_batch, G_input_dim).view(-1, G_input_dim, 1, 1)\n",
        "        z_ = Variable(z_.cuda())\n",
        "        gen_image = G(z_)\n",
        "\n",
        "        D_fake_decision = D(gen_image).squeeze()\n",
        "        D_fake_loss = criterion(D_fake_decision, y_fake_)\n",
        "\n",
        "        # Back propagation\n",
        "        D_loss = D_real_loss + D_fake_loss\n",
        "        D.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_optimizer.step()\n",
        "\n",
        "        # Train generator\n",
        "        z_ = torch.randn(mini_batch, G_input_dim).view(-1, G_input_dim, 1, 1)\n",
        "        z_ = Variable(z_.cuda())\n",
        "        gen_image = G(z_)\n",
        "\n",
        "        D_fake_decision = D(gen_image).squeeze()\n",
        "        G_loss = criterion(D_fake_decision, y_real_)\n",
        "\n",
        "        # Back propagation\n",
        "        D.zero_grad()\n",
        "        G.zero_grad()\n",
        "        G_loss.backward()\n",
        "        G_optimizer.step()\n",
        "\n",
        "        # loss values\n",
        "        D_losses.append(D_loss.data[0])\n",
        "        G_losses.append(G_loss.data[0])\n",
        "\n",
        "        print('Epoch [%d/%d], Step [%d/%d], D_loss: %.4f, G_loss: %.4f'\n",
        "              % (epoch+1, num_epochs, i+1, len(data_loader), D_loss.data[0], G_loss.data[0]))\n",
        "\n",
        "    D_avg_loss = torch.mean(torch.FloatTensor(D_losses))\n",
        "    G_avg_loss = torch.mean(torch.FloatTensor(G_losses))\n",
        "\n",
        "    # avg loss values for plot\n",
        "    D_avg_losses.append(D_avg_loss)\n",
        "    G_avg_losses.append(G_avg_loss)\n",
        "\n",
        "    plot_loss(D_avg_losses, G_avg_losses, epoch, save=True)\n",
        "\n",
        "    # Show result for fixed noise\n",
        "    plot_result(G, fixed_noise, epoch, save=True, fig_size=(5, 5))\n",
        "\n",
        "    G_save_path = f'./DCGAN/models/gdcgan{epoch}.pth'\n",
        "    D_save_path = f'./DCGAN/models/ddcgan{epoch}.pth'\n",
        "    torch.save(G.state_dict(), G_save_path)\n",
        "    torch.save(D.state_dict(), D_save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuVPsQEFtcKW",
        "colab_type": "text"
      },
      "source": [
        "####Run Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU8FGck5uFLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_example(test_num, generator, noise, num_epoch, save=False, save_dir='./DCGAN/results/', show=False, fig_size=(5, 5)):\n",
        "    generator.eval()\n",
        "\n",
        "    noise = Variable(noise.cuda(), volatile=True)\n",
        "    gen_image = generator(noise)\n",
        "    gen_image = denorm(gen_image)\n",
        "\n",
        "    n_rows = np.sqrt(noise.size()[0]).astype(np.int32)\n",
        "    n_cols = np.sqrt(noise.size()[0]).astype(np.int32)\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=fig_size)\n",
        "    for ax, img in zip(axes.flatten(), gen_image):\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box')\n",
        "        img = (((img - img.min()) * 255) / (img.max() - img.min())).cpu().data.numpy().transpose(1, 2, 0).astype(np.uint8)\n",
        "        ax.imshow(img, cmap=None, aspect='equal')\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    title = 'Epoch {0}'.format(num_epoch+1)\n",
        "    fig.text(0.5, 0.04, title, ha='center')\n",
        "\n",
        "    # save image\n",
        "    if save:\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.mkdir(save_dir)\n",
        "        save_fn = save_dir + 'image_test_{:d}'.format(test_num) + '.png'\n",
        "        plt.savefig(save_fn)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md8AtorGlMKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = ''\n",
        "G.load_state_dict(torch.load(PATH))\n",
        "\n",
        "xzy_noise= torch.randn(1, G_input_dim).view(-1, G_input_dim, 1, 1)\n",
        "xzy_noise = Variable(xzy_noise.cuda())\n",
        "gen_image = G(xzy_noise)\n",
        "plot_example(69, G, fixed_noise, epoch, save=True, fig_size=(5, 5))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}